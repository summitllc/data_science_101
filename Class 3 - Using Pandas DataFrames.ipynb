{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068031f-3ed2-497a-948a-ca312abc6499",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "994a2a26-5b42-4d8b-8a3c-19bdb89b6c1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using Pandas DataFrames\n",
    "\n",
    "This notebook focuses on using Dataframes, which is the primary data structure that Pandas adds to python. We will discuss the various parts of a Pandas Dataframe and how to create, manipulate, and edit a dataframe. \n",
    "\n",
    "For this section, we are going to be using the data located at  \n",
    "> https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas/master/ch_02/data/parsed.csv\n",
    "\n",
    "This dataset will be used for all of the exersises.\n",
    "\n",
    "\n",
    "## What is a Dataframe\n",
    "\n",
    "The most widely understood analogy when describing a Pandas Dataframe is to an spreadsheet. In a spreadsheet (be it excel, google sheet, or whatever version you prefer), you have rows, columns, and entries. In fact, Pandas uses this same vocabulary when referring to the various peices of a Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5deb6-a393-427a-a360-9cef6d4085a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas/master/ch_02/data/parsed.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "454ebed2-1e67-46ee-9e8a-aab40a54f65c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For this example dataframe we are going to be using for this file, we note that the whole table has 27 columns and 9332 rows. We can also get information about what data type each columns contains. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f8535-f1b0-4ec6-bfc9-b23be13fbcdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9775f301-dc12-46fb-91ae-85ba72ce412b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this dataframe, we have integers, floats, and strings (here labeled as `object`). We can extract any one of these columns by referencing the column's name or `index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebded2-9352-469e-842e-eae36ef8e9ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.place"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ac9bf8f-4bbf-4db5-8a3e-e97cb01c2a8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, we can reference the column by using a key, similar to Python dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03847b5-23a8-4ac7-ae8c-fecd0b4dd7b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"place\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13dc350b-1e30-4256-afb8-a27b9a1ffd1f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This single column is no longer a `DataFrame`, but instead is the class object `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949edcb4-4395-408b-8d70-c16f5ebbec88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df))\n",
    "print(type(df.place))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db9080ed-dbb2-42fc-99b9-7e878ed0c859",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A `DataFrame` object is simply a collection of `Series` objects. All objects in a `Series` have to have the same data type, and a `DataFrame` can be made up of whatever series objects you wish.\n",
    "\n",
    "An additional object that makes up both the `Series` and the `DataFrame` is the `Index`. Notice that on every one of the above outputs, you can see the numbers 0-9331. This list of numbers is the `Index` for each `Series`. Each value in the `Index` is the index of that row or value. For `Series` objects, we can reference a particular value by its index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8df151-f668-4220-91db-b4b3de605d34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df.place[3]\n",
    "df.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53211fff-71cc-4cfd-a5b8-7b34801e29cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, if we try to do the same thing for a `DataFrame`, we get the following error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37239149-8129-4035-9be4-5312c0732c51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce059598-8166-450f-94bd-df239ce251fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is because the above syntax is trying to refer to the column name. To reference an entire row of a dataframe, you must use the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca0e12-8279-48fd-9c67-c10721b7bb38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca5f7cd-b30c-4337-b3ca-b426955c842f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The column names can be retrieved by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c93772-331b-4635-9dfa-c56a9c45c18e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97ed8311-c2f3-4df8-a3da-fc637c9521d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we need to refernce multiple columns at once, we can pass in a list of column names into square brackets. This will return a new dataframe of just the subset of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b48fe2-b77e-4f2e-a81e-288d1f4653e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"time\",\"mag\", \"magType\", \"place\", \"parsed_place\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f3e8199-1676-4365-a69a-99d8264afd40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using DataFrames\n",
    "\n",
    "Python has a reputation for being very slow. This is due to the fact that \n",
    "1. it is not a compiled language like C or C++\n",
    "2. there is a lot of extra bits on the backend that might not be present in a lower level language. \n",
    "\n",
    "For most scripting use cases, neither of these poses a problem. If you are doing any sort of high volume numerical computations, this will really slow down your workflow. To fix this, the python community created the NumPy package. This package trims down numbers to simply the actual number, offers in more matrix- and vector-like functionality (element-wise addition, vetor products, matrix multiplication, etc.), and many other functions to enable faster numerical computations. Pandas builds upon that base to bring in many of the same speed and functionality benefits into dataframes. To this end, we can operate on entire columns, build entirely new columns based on the values of already existing ones, filter rows based on the value of a single column, etc.\n",
    "\n",
    "### Adding new Columns\n",
    "Let's first build a new column. I want to determine if an earthquake occured on the Ring of Fire. The locations that make up the Ring of Fire are saved in the following list (inlcuding a mix of country and US State names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4285fe-3190-4b52-915e-105facf1ba9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ring_of_fire = [ \n",
    "    \"Bolivia\", \n",
    "    \"Chile\", \n",
    "    \"Ecuador\", \n",
    "    \"Peru\", \n",
    "    \"Costa Rica\", \n",
    "    \"Guatemala\", \n",
    "    \"Mexico\", \n",
    "    \"Japan\", \n",
    "    \"Philippines\", \n",
    "    \"Indonesia\", \n",
    "    \"New Zealand\", \n",
    "    \"Antarctic\", \n",
    "    \"Canada\", \n",
    "    \"Fiji\", \n",
    "    \"Alaska\", \n",
    "    \"Washington\", \n",
    "    \"California\", \n",
    "    \"Russia\", \n",
    "    \"Taiwan\", \n",
    "    \"Tonga\", \n",
    "    \"Kermadec Islands\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75eedcc-5fe2-4ea1-b1a4-27e35a67c0ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking a look at the column `parsed_place`, we note that these names best match to that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518f0b1-13c1-4ead-a636-b55c334fe195",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.parsed_place.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce800834-847c-4e92-8312-520cade6c90b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One way of determining if a value is in a given list is by using the `value in list` syntax. Using this, we are essentially asking of a particular value exists within that list. This would look like the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e96b2-7f8d-40a8-8165-5da26c26e332",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"North Carolina\" in df.parsed_place.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c5e8429-c0ad-4fad-8c61-a2cc54e6719f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This tells us that at least one row has the value `'North Carolina'` in the `parsed_place` column of our dataset. However, what we need to do is build a series of values for true and false based on the value of that particular row. For this we can use a feature called list comprehension. This one-liner trick builds a list very efficently, which we can later convert into a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4fc90d-66e1-4c03-9df6-660c29aee6f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ring_of_fire_column_list = [location in ring_of_fire for location in df.parsed_place]\n",
    "print(\"length:\", len(ring_of_fire_column_list))\n",
    "print(\"unique:\", set(ring_of_fire_column_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af6d31e4-d871-4667-949b-8698eb105125",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Perfect, now we have a list of true/false values with the same number of values as the number of rows in our dataset. Converting this into a series is done simply by instanctiating the class from the Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf21ff-aec0-44d7-a58e-1c46fbcf01aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ring_of_fire_column = pd.Series(ring_of_fire_column_list, name=\"is_in_ring_of_fire\")\n",
    "ring_of_fire_column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33b7522e-3793-4edf-9191-c2ccd4b804cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pandas is a very versitile library and is able adapt its functionality based on the inputs. Here we were able to convert out list into a Series. We can add our series to the original dataframe by using the `join` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02997d8-0f31-4ac5-9488-cf30c299be01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_join = df.join(ring_of_fire_column)\n",
    "df_join[[\"parsed_place\",\"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f94c6-3ace-4c07-b161-2df619656c48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_join.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96d54222-c942-4302-abca-afdb9e556354",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now see that the column has been added to the dataframe. \n",
    "\n",
    "_Note: that the dataframe has to be saved again after the joining. Dataframes are imutible (unchangeable) objects in python. Therefore, you need to resave the dataframe after making a change like dropping or adding columns or filtering rows._\n",
    "\n",
    "An alternate (and slightly simpler) way of adding the column is by assigning the list directly to a new key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc736f-912c-40b7-8cff-e9b40ad98d20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['is_in_ring_of_fire'] = ring_of_fire_column_list\n",
    "df[[\"parsed_place\", \"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9acf8c56-b5aa-434c-aa2b-139b079f53c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Filtering rows\n",
    "Filtering rows works by creating a series or list of boolean values, and passing that in as the index argument. This can be either the value of a boolean column, such as the `is_in_ring_of_fire` column we created in the last section. Alternatively, you can filter based on some condition regarding the value of the entry, such as is the magnitude higher than some value. Let's explore both of these options below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b798771-e72b-4e6f-955e-ba9c019ab1e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df.is_in_ring_of_fire][[\"parsed_place\",\"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "940e6df7-4360-4655-8341-f6e629f69081",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that the number of rows is smaller by ~2000. To make this even more dramatic, let's show all the rows that are _not_ in the ring of fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f231aa-74f8-473d-af12-2801f8bdaaa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df.is_in_ring_of_fire == False][[\"parsed_place\",\"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceabfcf1-2de0-4fd9-ab2d-a951cd2d3b85",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have just over 2000 rows, which lines up roughly with what we noticed before. Notice that we could have used the same syntax for the true case, specificaly, `df.is_in_ring_of_fire == True`. Also notice that the index of the row does not change. The index still points back to the row number of the original dataframe, or the row number is specifically connected to the data, and is not simply a counter. There are ways of reassigning the index, but that is not something I want to explore for this class. \n",
    "\n",
    "Note that we used the equality operator (`==`) when filtering on this second row. This suggestes that we can use other comparison operators for different values as well. Rather, we can use any operator that returns an array boolean values. To clarify what I mean, let's look at the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74043284-45ea-45cf-b734-4d236142fe7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.is_in_ring_of_fire == True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37af37a2-bd5c-455e-aa2d-1f12f63a2a7e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The above value is a Pandas Series. Coensidentially, it is the set of values as the column that we created. This suggests that any list we create can be used to filter. We could use the following to get the same filter instead of creating a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60a12f-0197-4c4a-a73d-97837bf452fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[location in ring_of_fire for location in df.parsed_place]][[\"parsed_place\",\"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0237bd6b-18ef-40f9-ae5c-e87489eb9760",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the same result in fewer lines of code, which can be very helpful if we are pressed for computation time, or we just don't need to add more data for python to manage. \n",
    "\n",
    "Another way we can filter our data is through numerical comparisons. Note the following series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3b830-bbdc-4765-a0f3-d0dd6448499c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.mag >= 2.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63ded3b7-9308-443d-b24c-0ab8f18d875d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use something like this to find just the earthquakes that are above a certain threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3b063-be71-4b00-9fe8-3e029bb41a5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df.mag >= 5.0][[\"parsed_place\",\"is_in_ring_of_fire\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1e3f7b-8acf-414e-8c4c-8b5a0b8e0ab9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By this point, we can start combining all sorts of conditions on the dataset to zero in on the specific rows that you need for your analysis. Let's find all the earthquakes that hit Indonesia that were also coupled with a tsunami. The first part of this filter is easy. Simply find all the rows where `df.parsed_place == \"Indonesia\"`, very similar to filters we have already performed. For the second part, let's first take a look at the values present in `df.tsunami`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d1681-59da-4bfe-9c0a-0b2c82a82afa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.tsunami.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17ab28f4-7876-4ea3-b852-115ebd6439ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Out of all 9000+ rows, only two values exist: zero and one. Sometimes, a boolean value is stored as integers. If this is the case, the standard translation is `0 == False` and `1== True`. We could have python convert the values of this column to an actual boolean type, but that would be an unnecessary extra step. We can simply use `df.tsunami == 1` to find all the rows where a tsunami was also triggered by the earthquake. \n",
    "\n",
    "To use both filters, there are a couple different ways of managing this. The simplist would be to use the method `loc`. This method allows us to select a subset of columns and combine the filters together using simple and/or operators. For this problem, you could execute the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05cbcd-dbc1-4575-963a-a9eb98c969f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[ \n",
    "    (df.parsed_place == \"Indonesia\") & (df.tsunami == 1),\n",
    "    [\"parsed_place\", \"is_in_ring_of_fire\"]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13f9dcfd-c272-44d0-a9c5-737dfa0830c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_Note: `loc` can also be used to select specific row numbers if that is known. This will work based on the index of the row, not the position in the dataframe. Read [this StackOverflow question](https://stackoverflow.com/questions/31593201/how-are-iloc-and-loc-different) for a more detailed explanation, along with a comparison of another method `iloc`._\n",
    "\n",
    "### Summary Statistics\n",
    "\n",
    "One main point of using large datasets is for calculating statistical values, such as averages and spread. Methods to compute these values are build directly into the `DataFrame` and `Series` classes. They can be accessed by calling the appropriate methods. Doing so returns a series of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540b22c-3ecc-4378-a63d-f10db286d8a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Count non-empty:\")\n",
    "print(df.count(), end=\"\\n----------------------------------\\n\\n\")\n",
    "print(\"Mean:\")\n",
    "print(df.mean(), end=\"\\n----------------------------------\\n\\n\")\n",
    "print(\"Standard Deviation:\")\n",
    "print(df.std(), end=\"\\n----------------------------------\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7c5884c-1f8f-4404-a26b-45469d0d539a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The above are warning coming from Pandas, letting us know that the current syntax that we are using will soon be deprecated. The following table shows some of the more common methods that you might use on a table or series to gather some high level information about the data. \n",
    "\n",
    "| Method | Description | Data types |\n",
    "| - | - | - |\n",
    "| `count()` | The number of non-null observations | Any |\n",
    "| `nunique()` | The number of unique values | Any |\n",
    "| `sum()` | The toal of the values | Numeric or Boolean | \n",
    "| `mean()` | The average of the values | Numerical or Boolean | \n",
    "| `meadian()` | The median of the values | Numerical | \n",
    "| `min()` | The minimum of the Values | Numerical | \n",
    "| `idxmin()` | The index where the minimum value occurs | Numerical | \n",
    "| `max()` | The maximum of the values | Numerical | \n",
    "| `idxmax()` | The index where the maximum value occurs | Numerical | \n",
    "| `abs()` | The absolute value of the values | Numerical | \n",
    "| `std()` | The standard deviation | Numerical | \n",
    "| `var()` | The variance | Numerical | \n",
    "| `cov()` | The covariance between two `Series`, or a covariance matrix for all column combinations in a DataFrame | Numerical |\n",
    "| `corr()` | The correlation between two `Series`, or a correlation matrix for all column combinations in a `DataFrame` | Numerical | \n",
    "| `quantril()` | Gets a specific quantrile | Numerical | \n",
    "| `cumsum()` | The cumulative sum | Numerical or Boolean | \n",
    "| `cummin()` | The cumulative minimum | Numerical | \n",
    "| `cummax()` | The cumulative maximum | Numerical |\n",
    "\n",
    "A handful of these values can be calculated and displayed all at once by just the `discribe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b0d11-b7a5-4b73-a7b8-068e625da3f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2bca029-4346-476c-b6bf-72750cb5d4dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This provides some of the most common values that used in statistial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b39411-1ac7-44dd-acea-744f90c1b21e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
